# Awesome-LLM-Application

## Table of Content
-----

- [Awesome-LLM-Application]
  - [Input UI](#input-ui)
  - [Input Augment](#input-augment)
  - [Model Augment](#model-augment)
  - [RAG-system](#rag-system)
  - [LLM serving](#llm-serving)
  - [LLM evaluate system](#llm-evaluate-system)


## Input UI
----
### Blogs
### Trending Projects
- [Flowise](https://github.com/FlowiseAI/Flowise)
- [chainlit](https://github.com/Chainlit/chainlit)
- [autogen-ui](https://github.com/victordibia/autogen-ui)
- [langui](https://github.com/ahmadbilaldev/langui)
### Companys

## Input Augment
-----
### Blogs
|title|content|updated time|
|-----|-------|------------|
|[使用 Langchain 的 LLM 的对话记忆](https://zhuanlan.zhihu.com/p/639480745)||25/06/2023|

## Model Augment

### Blogs
|title|content|domain|updated time|
|-----|-------|--------|----------|
|[Calculate GPU Requirements for Your LLM Training](https://medium.com/@plthiyagu/calculate-gpu-requirements-for-your-llm-training-7122a3700547)||hardware|06/12/2023|
|[Large Language Models - The Hardware Connection](https://community.juniper.net/blogs/sharada-yeluri/2023/10/03/large-language-models-the-hardware-connection?CommunityKey=44efd17a-81a6-4306-b5f3-e5f82402d8d3)||hardware|03/10/2023|
## RAG System
-----
### Blogs
|blog|content|updated time
|-----|------|-------|
|[The architecture of today’s LLM applications](https://github.blog/2023-10-30-the-architecture-of-todays-llm-applications/)||30/10/2023
|[Building RAG-based LLM Applications for Production](https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1)||25/10/2023
### papers
### Frameworks


### companys

## LLM Serving
-----
### Blogs
|title|content|domain|updated time|
|-----|------|-------|-----------|
|[A guide to LLM inference and performance](https://www.baseten.co/blog/llm-transformer-inference-guide/)||hardware|07/11/2023|
|[A Comprehensive Guide to Selecting and Estimating GPUs for Serving ML Models](https://medium.com/@samuel-taiwo/a-comprehensive-guide-to-selecting-and-estimating-gpus-for-serving-ml-models-23d2874dcbd8)||hardware|05/07/2023|
|[7 Frameworks for Serving LLMs](https://betterprogramming.pub/frameworks-for-serving-llms-60b7f7b23407)|||31/7/2023|
|[Optimized large language model (LLM) serving
|[大语言模型的模型量化(INT8/INT4)技术](https://zhuanlan.zhihu.com/p/627436535)||quant|6/7/2023|
|[NVIDIA HPC Application Performance](https://developer.nvidia.com/hpc-application-performance)||hardware|/|


### Trending Frameworks
- [Text Generation Inference](https://huggingface.co/docs/text-generation-inference/index)
- [vLLM](https://github.com/vllm-project/vllm)
- [OpenLLM](https://github.com/bentoml/OpenLLM)
- [mlc-llm](https://github.com/mlc-ai/mlc-llm)
- [ollama](https://github.com/ollama/ollama)


### papers
|title|content|domain|conference|data|
|-----|-------|-------|----------|-----|
|[ServerlessLLM: Locality-Enhanced Serverless Inference for Large Language Models](https://arxiv.org/abs/2401.14351)|||25/1/2024|
|[FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness](https://arxiv.org/abs/2205.14135)|||27/05/2023|
|[FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning](https://arxiv.org/abs/2307.08691)||||
|[Efficient memory management for large language model serving with pagedattention](https://dl.acm.org/doi/pdf/10.1145/3600006.3613165)||||




### Frameworks

## LLM Evaluate
-----

## others

### blogs
